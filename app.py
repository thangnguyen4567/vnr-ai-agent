import streamlit as st
from dotenv import load_dotenv
from src.core.multi_agent import multi_agent_graph as graph
import asyncio
from typing import AsyncGenerator
from src.core.config_loader import agent_config_loader
# Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# Thi·∫øt l·∫≠p ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
st.set_page_config(page_title="AI Chatbot", page_icon="ü§ñ")
st.title("ü§ñ AI Chatbot")
agent_config_loader.set_agent_type("multi")
# Kh·ªüi t·∫°o chat history trong session state n·∫øu ch∆∞a c√≥
if "messages" not in st.session_state:
    st.session_state.messages = []

# Kh·ªüi t·∫°o config trong session state n·∫øu ch∆∞a c√≥
if "config" not in st.session_state:
    st.session_state.config = {
        'user_id': '1234567890',
        'user_name': 'Thang',
        'current_date': '06/06/2025',
        'language': 'vi-VN',
        'agent_id': 'd4e12d5bb4014794fa3f956e2b0e01cf'
    }

async def process_message():
    async for event in graph.astream_events(inputs, config=st.session_state.config):
        kind = event['event']

        if kind == "on_custom_event":
            thinking_content = event['data']['data']['text']
            yield thinking_content

        elif kind == "on_chat_model_stream" and event["metadata"].get("langgraph_node") not in ["research","reflection"]:
            answer_content = event['data']['chunk'].content
            if answer_content:
                yield answer_content

def to_sync_generator(async_gen: AsyncGenerator):
    # 1. T·∫°o m·ªõi m·ªôt loop
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        while True:
            try:
                # Ch·∫°y 1 b∆∞·ªõc c·ªßa async gen
                yield loop.run_until_complete(async_gen.__anext__())
            except StopAsyncIteration:
                break
    finally:
        # H·ªßy loop khi xong
        loop.close()
        # Tr·∫£ l·∫°i setting ban ƒë·∫ßu (n·∫øu c·∫ßn)
        asyncio.set_event_loop(None)


# Hi·ªÉn th·ªã tin nh·∫Øn tr∆∞·ªõc ƒë√≥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"], unsafe_allow_html=True)

# Giao di·ªán chat
if prompt := st.chat_input("Nh·∫≠p tin nh·∫Øn c·ªßa b·∫°n..."):
    # Th√™m tin nh·∫Øn ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Hi·ªÉn th·ªã ƒëang x·ª≠ l√Ω
    with st.chat_message("assistant"):
        inputs = {"messages": [("user", prompt)]}
        message_placeholder = st.empty()
        response = st.write_stream(to_sync_generator(process_message()))





